//
//  ChatView.swift
//  VibrantFrog
//
//  Chat interface for interacting with photos via MCP tools
//

import SwiftUI

struct ChatMessage: Identifiable, Equatable {
    let id = UUID()
    let role: MessageRole
    let content: String
    let timestamp: Date
    var toolResult: ToolResult?

    enum MessageRole {
        case user
        case assistant
        case system
    }

    struct ToolResult: Equatable {
        let toolName: String
        let photos: [PhotoResult]?
        let albums: [String]?
        let text: String?

        struct PhotoResult: Equatable, Identifiable {
            let id = UUID()
            let uuid: String
            let filename: String
            let description: String
            let relevance: Double
        }
    }
}

@MainActor
class ChatViewModel: ObservableObject {
    @Published var messages: [ChatMessage] = []
    @Published var inputText: String = ""
    @Published var isProcessing: Bool = false
    @Published var errorMessage: String?

    let mcpClient: MCPClientHTTP

    init(mcpClient: MCPClientHTTP) {
        self.mcpClient = mcpClient

        // Add welcome message
        messages.append(ChatMessage(
            role: .system,
            content: "Welcome to VibrantFrog! I can help you search and organize your photos. Try asking me to:\n\nâ€¢ Search for photos (e.g., \"show me beach photos\")\nâ€¢ Create albums (e.g., \"create an album from sunset photos\")\nâ€¢ List your albums\nâ€¢ Get photo details",
            timestamp: Date()
        ))
    }

    func sendMessage() async {
        guard !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else { return }

        let userMessage = inputText
        inputText = ""

        // Add user message
        messages.append(ChatMessage(
            role: .user,
            content: userMessage,
            timestamp: Date()
        ))

        isProcessing = true
        errorMessage = nil

        defer {
            isProcessing = false
        }

        do {
            // Simple intent detection
            let intent = detectIntent(userMessage)
            let response = try await handleIntent(intent, query: userMessage)

            messages.append(response)

        } catch {
            errorMessage = error.localizedDescription
            messages.append(ChatMessage(
                role: .assistant,
                content: "I encountered an error: \(error.localizedDescription)",
                timestamp: Date()
            ))
        }
    }

    private func detectIntent(_ message: String) -> Intent {
        let lower = message.lowercased()

        if lower.contains("search") || lower.contains("find") || lower.contains("show me") {
            return .search
        } else if lower.contains("create album") || lower.contains("make album") {
            return .createAlbum
        } else if lower.contains("list album") || lower.contains("show album") || lower.contains("my albums") {
            return .listAlbums
        } else if lower.contains("help") {
            return .help
        } else {
            // Default to search
            return .search
        }
    }

    private func handleIntent(_ intent: Intent, query: String) async throws -> ChatMessage {
        switch intent {
        case .search:
            return try await performSearch(query: query)

        case .createAlbum:
            return try await createAlbumFromSearch(query: query)

        case .listAlbums:
            return try await listAlbums()

        case .help:
            return ChatMessage(
                role: .assistant,
                content: """
                I can help you with:

                ðŸ“¸ **Search Photos**
                "Show me beach photos"
                "Find sunset pictures"
                "Search for dogs"

                ðŸ“ **Create Albums**
                "Create an album from beach photos"
                "Make an album of sunset pictures"

                ðŸ“‹ **List Albums**
                "List my albums"
                "Show all albums"

                Just ask naturally and I'll do my best to help!
                """,
                timestamp: Date()
            )
        }
    }

    private func performSearch(query: String) async throws -> ChatMessage {
        // Extract search terms from query
        let searchTerms = extractSearchTerms(from: query)

        // Call MCP search_photos tool
        let result = try await mcpClient.callTool(
            name: "search_photos",
            arguments: [
                "query": searchTerms,
                "n_results": 10
            ]
        )

        // Parse results
        guard let textContent = result.content.first(where: { $0.type == "text" }),
              let text = textContent.text else {
            throw ChatError.noResults
        }

        // Parse photo results from text
        let photos = parseSearchResults(text)

        let toolResult = ChatMessage.ToolResult(
            toolName: "search_photos",
            photos: photos,
            albums: nil,
            text: text
        )

        let responseText = if photos.isEmpty {
            "I couldn't find any photos matching '\(searchTerms)'. Try a different search term."
        } else {
            "I found \(photos.count) photos matching '\(searchTerms)':"
        }

        return ChatMessage(
            role: .assistant,
            content: responseText,
            timestamp: Date(),
            toolResult: toolResult
        )
    }

    private func createAlbumFromSearch(query: String) async throws -> ChatMessage {
        // Extract album name and search terms
        let (albumName, searchTerms) = extractAlbumNameAndSearch(from: query)

        // Call MCP create_album_from_search tool
        let result = try await mcpClient.callTool(
            name: "create_album_from_search",
            arguments: [
                "album_name": albumName,
                "search_query": searchTerms,
                "limit": 50
            ]
        )

        guard let textContent = result.content.first(where: { $0.type == "text" }),
              let text = textContent.text else {
            throw ChatError.toolFailed
        }

        return ChatMessage(
            role: .assistant,
            content: "âœ“ \(text)",
            timestamp: Date()
        )
    }

    private func listAlbums() async throws -> ChatMessage {
        // Call MCP list_albums tool
        let result = try await mcpClient.callTool(
            name: "list_albums",
            arguments: [:]
        )

        guard let textContent = result.content.first(where: { $0.type == "text" }),
              let text = textContent.text else {
            throw ChatError.toolFailed
        }

        // Parse album names
        let albumNames = parseAlbumList(text)

        let toolResult = ChatMessage.ToolResult(
            toolName: "list_albums",
            photos: nil,
            albums: albumNames,
            text: text
        )

        return ChatMessage(
            role: .assistant,
            content: text,
            timestamp: Date(),
            toolResult: toolResult
        )
    }

    // MARK: - Helper Methods

    private func extractSearchTerms(from query: String) -> String {
        let lower = query.lowercased()

        // Remove common prefixes
        var terms = lower
            .replacingOccurrences(of: "show me ", with: "")
            .replacingOccurrences(of: "find ", with: "")
            .replacingOccurrences(of: "search for ", with: "")
            .replacingOccurrences(of: "search ", with: "")
            .replacingOccurrences(of: "photos of ", with: "")
            .replacingOccurrences(of: "pictures of ", with: "")
            .replacingOccurrences(of: "images of ", with: "")

        return terms.trimmingCharacters(in: .whitespacesAndNewlines)
    }

    private func extractAlbumNameAndSearch(from query: String) -> (String, String) {
        let lower = query.lowercased()

        // Try to extract album name from patterns like "create an album called X from Y"
        if let range = lower.range(of: "called ") ?? lower.range(of: "named ") {
            let afterCalled = String(lower[range.upperBound...])
            if let fromRange = afterCalled.range(of: " from ") {
                let albumName = String(afterCalled[..<fromRange.lowerBound]).trimmingCharacters(in: .whitespacesAndNewlines)
                let searchTerms = String(afterCalled[fromRange.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
                return (albumName, searchTerms)
            }
        }

        // Default: extract search terms and generate name
        let searchTerms = extractSearchTerms(from: query)
        let albumName = searchTerms.capitalized + " Album"
        return (albumName, searchTerms)
    }

    private func parseSearchResults(_ text: String) -> [ChatMessage.ToolResult.PhotoResult] {
        var photos: [ChatMessage.ToolResult.PhotoResult] = []

        // Parse the text format from search_photos tool
        // Example: "1. filename.jpg\n   UUID: xxx\n   Description: ...\n   Relevance: 0.85\n\n"

        let lines = text.split(separator: "\n")
        var currentPhoto: (uuid: String, filename: String, description: String, relevance: Double)?

        for line in lines {
            let trimmed = line.trimmingCharacters(in: .whitespaces)

            if trimmed.starts(with: "UUID:") {
                currentPhoto?.uuid = String(trimmed.dropFirst(5).trimmingCharacters(in: .whitespaces))
            } else if trimmed.starts(with: "Description:") {
                currentPhoto?.description = String(trimmed.dropFirst(12).trimmingCharacters(in: .whitespaces))
            } else if trimmed.starts(with: "Relevance:") {
                if let relevanceStr = trimmed.split(separator: ":").last,
                   let relevance = Double(relevanceStr.trimmingCharacters(in: .whitespaces)) {
                    currentPhoto?.relevance = relevance

                    // Photo is complete, add it
                    if let photo = currentPhoto {
                        photos.append(ChatMessage.ToolResult.PhotoResult(
                            uuid: photo.uuid,
                            filename: photo.filename,
                            description: photo.description,
                            relevance: photo.relevance
                        ))
                    }
                    currentPhoto = nil
                }
            } else if trimmed.contains(".") && !trimmed.contains(":") {
                // This is likely a filename line like "1. photo.jpg"
                if let filename = trimmed.split(separator: ".").dropFirst().joined(separator: ".").split(separator: " ").last {
                    currentPhoto = (uuid: "", filename: String(filename), description: "", relevance: 0.0)
                }
            }
        }

        return photos
    }

    private func parseAlbumList(_ text: String) -> [String] {
        let lines = text.split(separator: "\n")
        return lines
            .filter { $0.trimmingCharacters(in: .whitespaces).starts(with: "-") }
            .map { String($0.trimmingCharacters(in: .whitespaces).dropFirst().trimmingCharacters(in: .whitespaces)) }
    }

    enum Intent {
        case search
        case createAlbum
        case listAlbums
        case help
    }
}

enum ChatError: LocalizedError {
    case noResults
    case toolFailed

    var errorDescription: String? {
        switch self {
        case .noResults:
            return "No results found"
        case .toolFailed:
            return "Tool execution failed"
        }
    }
}

struct ChatView: View {
    @EnvironmentObject var mcpClient: MCPClientHTTP
    @State private var messages: [ChatMessage] = []
    @State private var inputText: String = ""
    @State private var isProcessing: Bool = false
    @State private var errorMessage: String?
    @FocusState private var isInputFocused: Bool

    var body: some View {
        VStack(spacing: 0) {
            // Chat messages
            ScrollViewReader { proxy in
                ScrollView {
                    LazyVStack(alignment: .leading, spacing: 16) {
                        ForEach(messages) { message in
                            MessageBubble(message: message)
                                .id(message.id)
                        }

                        if isProcessing {
                            HStack {
                                ProgressView()
                                    .scaleEffect(0.8)
                                Text("Thinking...")
                                    .font(.caption)
                                    .foregroundStyle(.secondary)
                            }
                            .padding(.leading)
                        }
                    }
                    .padding()
                }
                .onChange(of: messages.count) { _ in
                    if let lastMessage = messages.last {
                        withAnimation {
                            proxy.scrollTo(lastMessage.id, anchor: .bottom)
                        }
                    }
                }
            }

            Divider()

            // Input area
            HStack(spacing: 12) {
                TextField("Ask about your photos...", text: $inputText)
                    .textFieldStyle(.plain)
                    .font(.body)
                    .focused($isInputFocused)
                    .onSubmit {
                        Task {
                            await sendMessage()
                        }
                    }
                    .disabled(isProcessing || !mcpClient.isConnected)

                Button {
                    Task {
                        await sendMessage()
                    }
                } label: {
                    Image(systemName: "arrow.up.circle.fill")
                        .font(.title2)
                        .foregroundStyle(inputText.isEmpty || !mcpClient.isConnected ? .secondary : .blue)
                }
                .buttonStyle(.plain)
                .disabled(inputText.isEmpty || isProcessing || !mcpClient.isConnected)
            }
            .padding()
            .background(Color(nsColor: .controlBackgroundColor))

            // Connection status
            if !mcpClient.isConnected {
                HStack {
                    Image(systemName: "exclamationmark.triangle.fill")
                        .foregroundStyle(.orange)
                    Text("Not connected to MCP server")
                    Button("Connect") {
                        Task {
                            try? await mcpClient.connect()
                        }
                    }
                }
                .font(.caption)
                .padding(.horizontal)
                .padding(.vertical, 8)
                .background(Color.orange.opacity(0.1))
            }
        }
        .navigationTitle("Chat")
        .onAppear {
            // Add welcome message on first load
            if messages.isEmpty {
                messages.append(ChatMessage(
                    role: .system,
                    content: "Welcome to VibrantFrog! I can help you search and organize your photos. Try asking me to:\n\nâ€¢ Search for photos (e.g., \"show me beach photos\")\nâ€¢ Create albums (e.g., \"create an album from sunset photos\")\nâ€¢ List your albums\nâ€¢ Get photo details",
                    timestamp: Date()
                ))
            }

            // Auto-connect if not connected
            if !mcpClient.isConnected {
                Task {
                    try? await mcpClient.connect()
                }
            }

            isInputFocused = true
        }
    }

    // MARK: - Message Handling

    private func sendMessage() async {
        guard !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty else { return }

        let userMessage = inputText
        inputText = ""

        // Add user message
        messages.append(ChatMessage(
            role: .user,
            content: userMessage,
            timestamp: Date()
        ))

        isProcessing = true
        errorMessage = nil

        defer {
            isProcessing = false
        }

        do {
            // Simple intent detection
            let intent = detectIntent(userMessage)
            let response = try await handleIntent(intent, query: userMessage)

            messages.append(response)

        } catch {
            errorMessage = error.localizedDescription
            messages.append(ChatMessage(
                role: .assistant,
                content: "I encountered an error: \(error.localizedDescription)",
                timestamp: Date()
            ))
        }
    }

    private func detectIntent(_ message: String) -> Intent {
        let lower = message.lowercased()

        if lower.contains("search") || lower.contains("find") || lower.contains("show me") {
            return .search
        } else if lower.contains("create album") || lower.contains("make album") {
            return .createAlbum
        } else if lower.contains("list album") || lower.contains("show album") || lower.contains("my albums") {
            return .listAlbums
        } else if lower.contains("help") {
            return .help
        } else {
            // Default to search
            return .search
        }
    }

    private func handleIntent(_ intent: Intent, query: String) async throws -> ChatMessage {
        switch intent {
        case .search:
            return try await performSearch(query: query)

        case .createAlbum:
            return try await createAlbumFromSearch(query: query)

        case .listAlbums:
            return try await listAlbums()

        case .help:
            return ChatMessage(
                role: .assistant,
                content: """
                I can help you with:

                ðŸ“¸ **Search Photos**
                "Show me beach photos"
                "Find sunset pictures"
                "Search for dogs"

                ðŸ“ **Create Albums**
                "Create an album from beach photos"
                "Make an album of sunset pictures"

                ðŸ“‹ **List Albums**
                "List my albums"
                "Show all albums"

                Just ask naturally and I'll do my best to help!
                """,
                timestamp: Date()
            )
        }
    }

    private func performSearch(query: String) async throws -> ChatMessage {
        // Extract search terms from query
        let searchTerms = extractSearchTerms(from: query)

        // Call MCP search_photos tool
        let result = try await mcpClient.callTool(
            name: "search_photos",
            arguments: [
                "query": searchTerms,
                "n_results": 10
            ]
        )

        // Parse results
        guard let textContent = result.content.first(where: { $0.type == "text" }),
              let text = textContent.text else {
            throw ChatError.noResults
        }

        // Parse photo results from text
        let photos = parseSearchResults(text)

        let toolResult = ChatMessage.ToolResult(
            toolName: "search_photos",
            photos: photos,
            albums: nil,
            text: text
        )

        let responseText = if photos.isEmpty {
            "I couldn't find any photos matching '\(searchTerms)'. Try a different search term."
        } else {
            "I found \(photos.count) photos matching '\(searchTerms)':"
        }

        return ChatMessage(
            role: .assistant,
            content: responseText,
            timestamp: Date(),
            toolResult: toolResult
        )
    }

    private func createAlbumFromSearch(query: String) async throws -> ChatMessage {
        // Extract album name and search terms
        let (albumName, searchTerms) = extractAlbumNameAndSearch(from: query)

        // Call MCP create_album_from_search tool
        let result = try await mcpClient.callTool(
            name: "create_album_from_search",
            arguments: [
                "album_name": albumName,
                "search_query": searchTerms,
                "limit": 50
            ]
        )

        guard let textContent = result.content.first(where: { $0.type == "text" }),
              let text = textContent.text else {
            throw ChatError.toolFailed
        }

        return ChatMessage(
            role: .assistant,
            content: "âœ“ \(text)",
            timestamp: Date()
        )
    }

    private func listAlbums() async throws -> ChatMessage {
        // Call MCP list_albums tool
        let result = try await mcpClient.callTool(
            name: "list_albums",
            arguments: [:]
        )

        guard let textContent = result.content.first(where: { $0.type == "text" }),
              let text = textContent.text else {
            throw ChatError.toolFailed
        }

        // Parse album names
        let albumNames = parseAlbumList(text)

        let toolResult = ChatMessage.ToolResult(
            toolName: "list_albums",
            photos: nil,
            albums: albumNames,
            text: text
        )

        return ChatMessage(
            role: .assistant,
            content: text,
            timestamp: Date(),
            toolResult: toolResult
        )
    }

    // MARK: - Helper Methods

    private func extractSearchTerms(from query: String) -> String {
        let lower = query.lowercased()

        // Remove common prefixes
        var terms = lower
            .replacingOccurrences(of: "show me ", with: "")
            .replacingOccurrences(of: "find ", with: "")
            .replacingOccurrences(of: "search for ", with: "")
            .replacingOccurrences(of: "search ", with: "")
            .replacingOccurrences(of: "photos of ", with: "")
            .replacingOccurrences(of: "pictures of ", with: "")
            .replacingOccurrences(of: "images of ", with: "")

        return terms.trimmingCharacters(in: .whitespacesAndNewlines)
    }

    private func extractAlbumNameAndSearch(from query: String) -> (String, String) {
        let lower = query.lowercased()

        // Try to extract album name from patterns like "create an album called X from Y"
        if let range = lower.range(of: "called ") ?? lower.range(of: "named ") {
            let afterCalled = String(lower[range.upperBound...])
            if let fromRange = afterCalled.range(of: " from ") {
                let albumName = String(afterCalled[..<fromRange.lowerBound]).trimmingCharacters(in: .whitespacesAndNewlines)
                let searchTerms = String(afterCalled[fromRange.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
                return (albumName, searchTerms)
            }
        }

        // Default: extract search terms and generate name
        let searchTerms = extractSearchTerms(from: query)
        let albumName = searchTerms.capitalized + " Album"
        return (albumName, searchTerms)
    }

    private func parseSearchResults(_ text: String) -> [ChatMessage.ToolResult.PhotoResult] {
        var photos: [ChatMessage.ToolResult.PhotoResult] = []

        // Parse the text format from search_photos tool
        let lines = text.split(separator: "\n")
        var currentPhoto: (uuid: String, filename: String, description: String, relevance: Double)?

        for line in lines {
            let trimmed = line.trimmingCharacters(in: .whitespaces)

            if trimmed.starts(with: "UUID:") {
                currentPhoto?.uuid = String(trimmed.dropFirst(5).trimmingCharacters(in: .whitespaces))
            } else if trimmed.starts(with: "Description:") {
                currentPhoto?.description = String(trimmed.dropFirst(12).trimmingCharacters(in: .whitespaces))
            } else if trimmed.starts(with: "Relevance:") {
                if let relevanceStr = trimmed.split(separator: ":").last,
                   let relevance = Double(relevanceStr.trimmingCharacters(in: .whitespaces)) {
                    currentPhoto?.relevance = relevance

                    // Photo is complete, add it
                    if let photo = currentPhoto {
                        photos.append(ChatMessage.ToolResult.PhotoResult(
                            uuid: photo.uuid,
                            filename: photo.filename,
                            description: photo.description,
                            relevance: photo.relevance
                        ))
                    }
                    currentPhoto = nil
                }
            } else if trimmed.contains(".") && !trimmed.contains(":") {
                // This is likely a filename line like "1. photo.jpg"
                if let filename = trimmed.split(separator: ".").dropFirst().joined(separator: ".").split(separator: " ").last {
                    currentPhoto = (uuid: "", filename: String(filename), description: "", relevance: 0.0)
                }
            }
        }

        return photos
    }

    private func parseAlbumList(_ text: String) -> [String] {
        let lines = text.split(separator: "\n")
        return lines
            .filter { $0.trimmingCharacters(in: .whitespaces).starts(with: "-") }
            .map { String($0.trimmingCharacters(in: .whitespaces).dropFirst().trimmingCharacters(in: .whitespaces)) }
    }

    enum Intent {
        case search
        case createAlbum
        case listAlbums
        case help
    }
}

struct MessageBubble: View {
    let message: ChatMessage

    var body: some View {
        HStack(alignment: .top, spacing: 12) {
            // Avatar
            Image(systemName: message.role == .user ? "person.circle.fill" : "sparkles")
                .font(.title2)
                .foregroundStyle(message.role == .user ? .blue : .green)
                .frame(width: 32, height: 32)

            VStack(alignment: .leading, spacing: 8) {
                // Message content
                Text(message.content)
                    .font(.body)
                    .textSelection(.enabled)

                // Tool results
                if let toolResult = message.toolResult {
                    ToolResultView(toolResult: toolResult)
                }

                // Timestamp
                Text(message.timestamp, style: .time)
                    .font(.caption2)
                    .foregroundStyle(.secondary)
            }
        }
        .padding(.vertical, 4)
    }
}

struct ToolResultView: View {
    let toolResult: ChatMessage.ToolResult

    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            // Photos grid
            if let photos = toolResult.photos, !photos.isEmpty {
                LazyVGrid(columns: [GridItem(.adaptive(minimum: 100))], spacing: 8) {
                    ForEach(photos.prefix(6)) { photo in
                        VStack(alignment: .leading, spacing: 4) {
                            RoundedRectangle(cornerRadius: 8)
                                .fill(Color.gray.opacity(0.2))
                                .frame(height: 100)
                                .overlay {
                                    Image(systemName: "photo")
                                        .font(.largeTitle)
                                        .foregroundStyle(.secondary)
                                }

                            Text(photo.filename)
                                .font(.caption2)
                                .lineLimit(1)
                        }
                    }
                }
                .padding(12)
                .background(Color.gray.opacity(0.05))
                .cornerRadius(8)

                if photos.count > 6 {
                    Text("+ \(photos.count - 6) more photos")
                        .font(.caption)
                        .foregroundStyle(.secondary)
                }
            }

            // Albums list
            if let albums = toolResult.albums, !albums.isEmpty {
                VStack(alignment: .leading, spacing: 4) {
                    ForEach(albums.prefix(10), id: \.self) { album in
                        HStack {
                            Image(systemName: "folder.fill")
                                .font(.caption)
                            Text(album)
                                .font(.body)
                        }
                    }
                }
                .padding(12)
                .background(Color.gray.opacity(0.05))
                .cornerRadius(8)
            }
        }
    }
}

#Preview {
    ChatView()
        .environmentObject(MCPClientHTTP())
        .frame(width: 600, height: 800)
}
