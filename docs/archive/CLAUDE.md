# VibrantFrog MCP - Project Overview for Claude

## What This Project Is

VibrantFrog is a **macOS application** that combines:
- **Apple Photos Library** access and management
- **Local LLM** (Ollama) with tool calling capabilities
- **MCP (Model Context Protocol)** server for photo indexing and semantic search
- **AI-powered photo chat interface** where users can ask natural language questions about their photos

The app allows users to search their photo library using natural language (e.g., "show me beach photos") and have an AI assistant find, display, and organize photos using MCP tools.

## Architecture

### Components

1. **VibrantFrog macOS App** (`/VibrantFrogApp/`)
   - SwiftUI interface
   - Uses Ollama for local LLM inference
   - Connects to Python MCP server via HTTP
   - Native PhotoKit integration for fast thumbnail loading
   - Bundle ID: `com.vibrantfrog.app`

2. **Python MCP Server** (`vibrant_frog_mcp.py`)
   - Provides tools for photo library operations
   - Uses ChromaDB for semantic vector search
   - Runs in HTTP mode on `http://127.0.0.1:5050`
   - Direct access to Apple Photos via `photoscript` library

3. **Photo Indexing** (`index_faces.py`, `cluster_faces.py`, etc.)
   - Batch processing scripts for photo library indexing
   - Face recognition and clustering
   - Uses llava:7b for image description generation

## Key Technologies

- **Swift/SwiftUI** - macOS app UI
- **PhotoKit** - Native Apple Photos library access
- **Ollama** - Local LLM runtime (llama3.2:latest, mistral:latest, llava:7b)
- **MCP (Model Context Protocol)** - Tool calling interface
- **ChromaDB** - Vector database for semantic search
- **Python photoscript** - Apple Photos AppleScript bridge
- **HTTP Transport** - MCP over HTTP (not stdio)

## Current State & Recent Work

### What's Working ‚úÖ

1. **MCP Server & Connection**
   - HTTP-based MCP server running on port 5050
   - Auto-connection from macOS app
   - 10 tools available: search_photos, get_photo, create_album, etc.
   - Type conversion fixes for Ollama parameters

2. **AI Chat Interface**
   - LLM (llama3.2) successfully calls MCP tools
   - Strong system prompt to enforce function calling
   - Conversation history maintained
   - Tool results displayed in chat

3. **Photo Links**
   - `photos://asset?uuid=XXX` URIs generated by MCP server
   - Clickable "Open in Photos" buttons in UI
   - Links successfully open photos in Photos.app

4. **Thumbnail Loading (JUST FIXED!)**
   - Native PhotoKit thumbnail loading
   - Fast, parallel loading of 10+ thumbnails
   - Clickable thumbnails that open in Photos.app
   - Proper app sandboxing with photo library entitlements

### What Was Just Fixed üîß

**Photo Library Permission Issue (Session Goal)**

**Problem**: VibrantFrog couldn't access Photos library - no permission dialog appeared, thumbnails failed to load.

**Root Cause**: App had sandbox **disabled** and was missing the `com.apple.security.personal-information.photos-library` entitlement.

**Solution**: Updated `VibrantFrog.entitlements` to match working PhotoOrganizerPro project:
```xml
<key>com.apple.security.app-sandbox</key>
<true/>
<key>com.apple.security.personal-information.photos-library</key>
<true/>
<key>com.apple.security.network.client</key>
<true/>
<key>com.apple.security.files.user-selected.read-write</key>
<true/>
```

**Result**: Permission dialog now appears on first launch, native PhotoKit works, fast thumbnail loading!

**File Changed**: `/Users/tpiazza/git/VibrantFrogMCP/VibrantFrogApp/VibrantFrog/VibrantFrog.entitlements`

### Known Issues & Limitations ‚ö†Ô∏è

1. **LLM Tool Calling Reliability**
   - llama3.2 sometimes outputs JSON text instead of calling tools
   - Strong system prompt helps but not 100% reliable
   - Temperature set to 0.3 for better tool calling
   - Consider trying mistral or qwen2.5 if issues persist

2. **Thumbnail Loading Performance**
   - Currently loads synchronously
   - Could be optimized with caching
   - Works well for 10-20 photos, might need optimization for larger batches

3. **Error Handling**
   - Limited error UI feedback
   - Console logging is verbose but user-facing errors could be clearer

## File Structure

```
VibrantFrogMCP/
‚îú‚îÄ‚îÄ vibrant_frog_mcp.py          # MCP server (main)
‚îú‚îÄ‚îÄ photo_retrieval.py           # Photo library access
‚îú‚îÄ‚îÄ index_faces.py               # Face indexing script
‚îú‚îÄ‚îÄ cluster_faces.py             # Face clustering
‚îú‚îÄ‚îÄ restart_http_server.sh       # Server restart helper
‚îú‚îÄ‚îÄ VibrantFrogApp/              # macOS app
‚îÇ   ‚îú‚îÄ‚îÄ VibrantFrog.xcodeproj
‚îÇ   ‚îî‚îÄ‚îÄ VibrantFrog/
‚îÇ       ‚îú‚îÄ‚îÄ Views/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ AIChatView.swift        # AI Chat tab (MAIN UI)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ PhotoSearchView.swift   # Search tab
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ SimpleChatView.swift    # Simple chat (no MCP)
‚îÇ       ‚îú‚îÄ‚îÄ Services/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ OllamaService.swift     # LLM interface
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ MCPClientHTTP.swift     # MCP connection
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ PhotoLibraryService.swift # PhotoKit wrapper
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ MCPServerRegistry.swift  # Server config
‚îÇ       ‚îú‚îÄ‚îÄ Info.plist                  # App permissions
‚îÇ       ‚îî‚îÄ‚îÄ VibrantFrog.entitlements    # Security entitlements
‚îî‚îÄ‚îÄ THUMBNAIL_IMPLEMENTATION.md  # Implementation notes
```

## Important Code Locations

### System Prompt for LLM
**File**: `VibrantFrog/Views/AIChatView.swift:182-211`
- Located in `setup()` function
- Very explicit about using function calling
- Includes examples of correct vs wrong behavior
- Can be modified to adjust LLM behavior

### Thumbnail Loading
**File**: `VibrantFrog/Services/PhotoLibraryService.swift:126-169`
- `loadThumbnailByUUID()` - Single thumbnail
- `loadThumbnailsByUUIDs()` - Batch loading
- Uses PHImageManager for fast native loading

### UUID Parsing & Display
**File**: `VibrantFrog/Views/AIChatView.swift:394-439`
- Parses UUIDs from MCP search results
- Loads thumbnails after tool execution
- Displays photo grid in MessageView

### MCP Tools Available
**File**: `vibrant_frog_mcp.py:262-390`
- `search_photos` - Semantic search (ChromaDB)
- `get_photo` - Retrieve photo as base64
- `create_album_from_search` - Auto-create albums
- `list_albums`, `add_photos_to_album`, etc.

## How to Continue Development

### Starting the App

1. **Start MCP Server**:
   ```bash
   cd /Users/tpiazza/git/VibrantFrogMCP
   ./restart_http_server.sh
   ```

2. **Launch macOS App**:
   - Open `VibrantFrogApp/VibrantFrog.xcodeproj` in Xcode
   - Run (Cmd+R)
   - Grant Photos permission on first launch

3. **Test AI Chat**:
   - Go to "AI Chat" tab
   - Ask: "show me beach photos"
   - Should see tool call, thumbnails, and links

### Making Changes

**To modify LLM behavior**:
- Edit system prompt in `AIChatView.swift:184-210`
- Adjust temperature in `OllamaService.swift:149`
- Try different models via `ollamaService.selectedModel`

**To add new MCP tools**:
1. Add tool definition in `vibrant_frog_mcp.py:@app.list_tools()`
2. Implement handler in `vibrant_frog_mcp.py:@app.call_tool()`
3. Restart MCP server
4. Tools auto-discovered by app on connect

**To improve thumbnail loading**:
- Add caching in `PhotoLibraryService.swift`
- Implement prefetching for better UX
- Consider lazy loading for large result sets

### Common Tasks

**Reset Photos Permission**:
```bash
tccutil reset Photos com.vibrantfrog.app
```

**Check Ollama Models**:
```bash
ollama list
```

**Test MCP Server Directly**:
```bash
curl -s -X POST http://127.0.0.1:5050/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","id":1,"method":"tools/list","params":{}}'
```

**Rebuild App After Entitlement Changes**:
```bash
cd VibrantFrogApp
xcodebuild -project VibrantFrog.xcodeproj -scheme VibrantFrog -configuration Debug clean build
```

## Related Projects

- **PhotoOrganizerPro** (`/Users/tpiazza/git/FrogTeamMCP/PhotoOrganizerPro`)
  - Reference implementation with working Photos permissions
  - Similar architecture but without MCP
  - Used as template for entitlements fix

## Next Steps (See next.md)

Potential improvements:
1. Add thumbnail caching
2. Implement progressive image loading
3. Add more MCP tools (edit metadata, batch operations)
4. Improve error handling and user feedback
5. Add conversation export/import
6. Support multiple MCP servers
7. Add photo editing capabilities

## Debug Tips

**If thumbnails don't load**:
- Check authorization status in console: `PHAuthorizationStatus(rawValue: 3)` = authorized
- Verify entitlements are enabled in Xcode project settings
- Check System Settings ‚Üí Privacy & Security ‚Üí Photos for VibrantFrog

**If LLM doesn't call tools**:
- Check console for "Tool calls: 0" vs "Tool calls: 1"
- Verify MCP tools loaded: "Fetched 10 MCP tools"
- Try strengthening system prompt or lowering temperature

**If MCP connection fails**:
- Verify server is running: `curl http://127.0.0.1:5050/mcp`
- Check for port conflicts: `lsof -i :5050`
- Restart server: `./restart_http_server.sh`

## Git Status (Last Known)

```
M vibrant_frog_mcp.py
?? FACE_RECOGNITION_GUIDE.md
?? VibrantFrogApp/
?? browse_faces_web.py
?? cluster_faces.py
?? index_faces.py
```

Main branch commits:
- d0d79c8 apple photo album support
- a5277c2 log memory restart ollama every 500 pics
- 9d9452c jpeg export fix web search fix

## Session Summary

This session focused on implementing native thumbnail loading for the AI Chat interface. The key breakthrough was discovering that VibrantFrog's entitlements were misconfigured compared to the working PhotoOrganizerPro project. After enabling app sandboxing and adding the photos-library entitlement, the permission dialog appeared and PhotoKit worked correctly, enabling fast native thumbnail loading.

The implementation now matches the original vision: LLM calls MCP tools ‚Üí parses UUIDs ‚Üí loads native thumbnails ‚Üí displays clickable photo grid.
