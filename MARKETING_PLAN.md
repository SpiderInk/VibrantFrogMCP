# üöÄ VibrantFrog Marketing Plan

## Overview
Marketing strategy for VibrantFrog - a native macOS AI chat application with MCP integration and AI-powered photo search.

---

## Phase 1: Immediate Launch (Days 1-3)

### 1. Developer Communities (High Priority)
These are your primary audience - developers interested in AI, local LLM, and MCP.

#### Reddit:
- **r/LocalLLaMA** (95k members) - Post: "Built a native macOS MCP client with AI-powered photo search"
- **r/MacApps** (50k members) - Post: "VibrantFrog: Native macOS AI chat with photo search via MCP"
- **r/swift** (80k members) - Post: "Open source SwiftUI app: AI chat with Model Context Protocol"
- **r/SideProject** (400k members) - Post: "Launched VibrantFrog - macOS AI chat with local LLM + photo search"

#### Example Reddit Post Template:
```
Title: Built VibrantFrog - Native macOS AI chat with MCP integration and photo search

I just launched VibrantFrog, a native macOS app that combines:
- AI chat via local Ollama models (privacy-focused, no API keys)
- Full Model Context Protocol (MCP) support
- AI-powered photo search using vector embeddings
- SwiftUI + Python MCP server (open source)

üîó GitHub: https://github.com/SpiderInk/VibrantFrogMCP
üì¶ Download v1.0.0: DMG/ZIP available

Key features:
- Works completely offline with Ollama
- Search your Apple Photos using natural language
- Connect to any MCP server (built-in: AWS Knowledge, photo search)
- Custom prompt templates
- 100% free and open source (MIT)

Looking for feedback! What MCP servers would you want to connect?
```

### 2. Hacker News (Critical - Can Drive Massive Traffic)
Post to Show HN: https://news.ycombinator.com/showhn.html

**Title:** "Show HN: VibrantFrog ‚Äì Native macOS AI chat with MCP and photo search"

**Post:**
```
I built VibrantFrog, a native macOS app for AI chat with full Model Context Protocol support.

Why I built this:
- Wanted a native Mac app for local LLMs (not Electron)
- Needed MCP integration beyond Claude Desktop
- Wanted to search my 10k+ photo library using AI

Tech stack:
- SwiftUI for native macOS UI
- Ollama for local LLM inference
- Python MCP server with ChromaDB for vector search
- Apple Photos Framework for library access

Key features:
- Privacy-first: everything runs locally
- Natural language photo search ("find beach photos from 2023")
- Connect to any MCP server via HTTP
- Custom prompt templates
- Open source (MIT)

Download: https://github.com/SpiderInk/VibrantFrogMCP/releases/tag/v1.0.0
Repo: https://github.com/SpiderInk/VibrantFrogMCP

Would love feedback from the HN community!
```

**Best time to post:** Tuesday-Thursday, 8-10am EST

### 3. Twitter/X (Tag Key Accounts)
```
üê∏ Just launched VibrantFrog v1.0!

A native macOS AI chat app with:
‚úÖ Local LLM via @OllamaAI
‚úÖ Model Context Protocol integration
‚úÖ AI-powered photo search
‚úÖ 100% open source

Download: https://github.com/SpiderInk/VibrantFrogMCP

#AI #macOS #MCP #LocalLLM #OpenSource

[Include screenshot: assets/screenshots/hero.png]
```

**Tag these accounts:**
- @AnthropicAI (created MCP)
- @OllamaAI (powers the app)
- @SwiftUILab (SwiftUI community)
- @locallama_ai (local LLM community)

### 4. Product Hunt (Major Launch Platform)
Submit to Product Hunt: https://www.producthunt.com/posts/new

**Preparation needed:**
- **Tagline:** "Native macOS AI chat with photo search and MCP integration"
- **Description:** (200 chars) "Privacy-first AI chat for Mac. Chat with local LLMs, search your photos using AI, and connect to any MCP server. Open source, works offline."
- **Media:** Upload screenshots + demo.gif
- **First comment:** Explain the "why" - your story of building it
- **Maker:** Your account
- **Topics:** AI, Developer Tools, Mac, Open Source, Productivity

**Best launch day:** Tuesday-Thursday (avoid Friday-Monday)
**Best time:** 12:01 AM PST (be there to respond to comments all day)

---

## Phase 2: Developer Outreach (Week 1)

### 5. MCP Community
- Post in Anthropic Discord (MCP channel)
- Email the MCP team at Anthropic (modelcontextprotocol@anthropic.com) - they feature community projects
- List on MCP Servers directory if they have one

### 6. Tech Blogs & Newsletters
Pitch story to:

#### Tech blogs:
- **9to5Mac** - "New open source Mac app brings AI photo search"
- **MacStories** - Federico Viticci loves Mac apps
- **The Verge** - Local AI + privacy angle
- **Ars Technica** - Technical deep dive angle

#### Email pitch template:
```
Subject: Story idea: Native macOS app for local AI with photo search

Hi [Name],

I just launched VibrantFrog, a native macOS app that combines local LLM chat (via Ollama) with AI-powered photo search.

What makes it newsworthy:
- Privacy-first: everything runs locally, no cloud/API needed
- Built on Model Context Protocol (Anthropic's new standard)
- Natural language photo search using vector embeddings
- 100% open source (MIT license)
- Native SwiftUI (not Electron)

I think your audience would be interested because [specific reason for their publication].

Would you be interested in covering it? Happy to provide additional details, screenshots, or a technical deep dive.

Links:
- GitHub: https://github.com/SpiderInk/VibrantFrogMCP
- Release: https://github.com/SpiderInk/VibrantFrogMCP/releases/tag/v1.0.0

Best,
[Your name]
```

#### Developer newsletters:
- **iOS Dev Weekly** - https://iosdevweekly.com
- **Swift Weekly** - https://swiftweekly.github.io
- **TLDR Newsletter** (AI section) - https://tldr.tech
- **The Pragmatic Engineer** - Gergely Orosz
- **Import AI** - Jack Clark (AI newsletter)

### 7. YouTube / Tech Influencers
Reach out to Mac/AI YouTubers:
- **MKBHD** - Too big, but worth a shot
- **Dave2D** - Covers interesting tech
- **The Linux Experiment** - Also covers Mac, privacy-focused
- **Andrej Karpathy** - If you can get him to try it (AI angle)
- **Fireship** - Might do a "100 seconds" video
- **ThePrimeagen** - Developer audience

#### Outreach template:
```
Hi [Name],

I built VibrantFrog - a native macOS app for AI chat that works completely offline using Ollama.

What makes it unique:
- Privacy-first (no cloud, no API keys)
- AI-powered photo search using your local Photos library
- Model Context Protocol support
- 100% open source

I think it might interest your audience because [reason]. Would you be interested in trying it out?

Happy to provide a demo, answer questions, or help in any way.

Download: https://github.com/SpiderInk/VibrantFrogMCP

Thanks,
[Your name]
```

---

## Phase 3: Content Marketing (Weeks 2-4)

### 8. Write Technical Blog Posts
Post on:
- **Dev.to** - "Building a native macOS MCP client in SwiftUI"
- **Medium** - "How I built AI photo search with vector embeddings"
- **Your own blog** - Link from forgoteam.ai or spiderink.net

#### Article ideas:
1. "Building a Model Context Protocol client in Swift"
2. "Implementing vector search for Apple Photos with ChromaDB"
3. "Why I chose local LLMs over cloud APIs"
4. "SwiftUI best practices from building VibrantFrog"
5. "The future of local-first AI applications"

### 9. Video Content
Create and upload to YouTube:
- **Demo video** (5 min) - Show all features
- **Setup tutorial** (10 min) - How to install and configure
- **Developer walkthrough** (20 min) - Code architecture tour
- **Photo search deep dive** (15 min) - How the MCP server works

### 10. GitHub Marketing
- Add to **awesome-mcp** lists (search GitHub for "awesome-mcp")
- Add to **awesome-macos** lists
- Add to **awesome-swiftui** lists
- Star and engage with related projects
- Comment on related issues in Ollama/MCP repos

---

## Phase 4: Community Building (Ongoing)

### 11. Engage in Communities
Active presence in:
- **r/LocalLLaMA** - Answer questions, share updates
- **Anthropic Discord** - Be helpful in MCP channels
- **Ollama Discord** - Share use cases
- **Swift Forums** - Discuss SwiftUI architecture

### 12. Regular Updates
- Post v1.1, v1.2 updates on all channels
- Share interesting use cases people find
- Highlight community contributions
- Monthly "What's new" blog posts

### 13. Documentation & Tutorials
- Create YouTube tutorials
- Write use case blog posts
- Build showcase gallery (user submissions)
- Create templates for common MCP servers

---

## Key Metrics to Track

1. **GitHub Stars** - Social proof
2. **Downloads** (release page) - Actual usage
3. **Issues/Discussions** - Community engagement
4. **Mentions/Backlinks** - Media coverage
5. **Forks** - Developer interest

---

## Quick Wins (Do Today)

1. ‚úÖ **Post to r/LocalLLaMA** - Biggest audience for this
2. ‚úÖ **Post to Hacker News** - Can drive 10k+ visitors
3. ‚úÖ **Tweet with @AnthropicAI and @OllamaAI tags**
4. ‚úÖ **Post in Anthropic Discord #mcp channel**
5. ‚úÖ **Submit to Product Hunt** (schedule for next Tuesday)

---

## Your Unique Angles

1. **Privacy-first**: Everything local, no cloud, no API keys
2. **Photo search**: Unique feature most AI chat apps don't have
3. **MCP native**: One of the first native Mac MCP clients
4. **Open source**: Full transparency, MIT license
5. **Native**: Real SwiftUI, not Electron (Mac users care!)

---

## Action Items

**Priority 1 (Today):**
1. Post to r/LocalLLaMA (highest ROI, takes 5 minutes)
2. Post to Hacker News Show HN (could get 500+ stars overnight)
3. Tweet with screenshots and tags
4. Schedule Product Hunt for next Tuesday

**Priority 2 (This Week):**
1. Post in Anthropic Discord
2. Email MCP team at Anthropic
3. Submit to iOS Dev Weekly
4. Reach out to 2-3 YouTubers

**Priority 3 (Next 2 Weeks):**
1. Write first technical blog post
2. Create demo video
3. Add to awesome lists
4. Pitch to tech blogs
